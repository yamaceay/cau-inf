{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Causal graph including noise variables\n",
    "\n",
    "* Intuition: the noise variables $\\eta_i$ substitutes all factors outside of the model in the form of a distribution $p(\\eta_1, …, \\eta_n)$. \n",
    "* The deterministic structural assignments transform this into a distribution $p(x_1, …, x_n)$ over the modeled variables $X$\n",
    "* Joint independence of $\\{\\eta_i\\}$, namely $p(\\eta_1, …, \\eta_n) = \\prod_i p(\\eta_i)$ means $X$ is large enough such that all dependencies among X are modeled explicitly by this structural assignments.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn causal relationships, typically in the form of the causal graph, from observational data given appropriate assumptions which are to be specified. \n",
    "\n",
    "The fundamental distinction between causal relationships and statistical relationships cf. the ladder of causation necessitates assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constraint-based:\n",
    "* The structure of the causal graph imposes constraints in the observational distribution, e.g. conditional independence.\n",
    "* Detect these constraints and use them to infer the causal graph.\n",
    "\n",
    "Score-based:\n",
    "* Devise a parametric function $Score(D, G)$ that assigns a numerical score to each graph G for the observed data D.\n",
    "* Choose the best scoring graph.\n",
    "\n",
    "SCM-based (bivariate case):\n",
    "* Make a parametric assumptions on noise distributions and the functional relationship between cause $C$ and effect $E$, namely on $f$ in $E := f (C , \\eta_E)$ such that $f$ cannot be inverted within the same function class.\n",
    "* Choose the direction yielding the better fit as causal. Can be generalized to multivariate case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data generation by SCM\n",
    "\n",
    "Assumption 1 (Data generation by SCM):\n",
    "* There is an SCM that generates the observational distribution p (observed) and interventional distributions (unobserved)\n",
    "* Reflects the view that the data generating process is a composition of autonomous causal mechanisms\n",
    "* May fail if individual mechanisms \n",
    "\n",
    "Assumption 2 (Acyclicity): \n",
    "* The data generating SCM is cyclic.\n",
    "* Many algorithms require this as a technical assumption, which is indeed a limitation. But for time-dependent processes it is easier to justify.\n",
    "* Recent development: Assumption can be relaxed.\n",
    "\n",
    "Corollary: Causal Markov condition\n",
    "\n",
    "If $\\cal C$ is an acyclic SCM, the causal graph $G = G(\\cal C)$ is a Bayesian network for the observational distribution $p$ generated by $\\cal C$:\n",
    "* $X \\bowtie Y | S \\implies X \\perp\\!\\!\\!\\perp Y | S$: d-separation implies independence\n",
    "* $X \\not\\perp\\!\\!\\!\\perp Y | S \\implies X \\not\\bowtie Y | S$: dependence implies d-connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumption 3 (Causal faithfulness)\n",
    "* Every independence in p is due to a d-separation in G:\n",
    "* $X \\perp\\!\\!\\!\\perp Y | S \\implies X \\bowtie Y | S$: independence implies d-separation\n",
    "\n",
    "Corollary: Assumptions 1 - 3 imply that conditional independence in the observational distribution is equivalent to d-separation in the causal graph.\n",
    "\n",
    "* $X \\perp\\!\\!\\!\\perp Y | S \\iff X \\bowtie Y | S$\n",
    "\n",
    "Discussion:\n",
    "* Most heavily criticized assumption of constraint-based causal discovery. \n",
    "* Certain relaxations to related but weaker assumptions possible. \n",
    "* Reflects the view that there are no accidental independencies due to tuned parameters\n",
    "* For linear models non-faithful distributions provably correspond to a measure zero subset of the parameter space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources of violations: \n",
    "\n",
    "1. Counteracting mechanisms:\n",
    "\n",
    "In this example $X \\perp\\!\\!\\!\\perp Y$ for $c = - a * b$ despite of d-connection. \n",
    "\n",
    "$X = \\eta_X, Y = aX + \\eta_Y, Z = bZ + cX + \\eta_Z$\n",
    "\n",
    "2. Determinism: \n",
    "\n",
    "For $X = f(Z)$ deterministic we get $l(X; Y | Z) = l(f(Z); Y | Z) = 0$ and thus $X \\perp\\!\\!\\!\\perp Y | Z$ even though $Y$ depends on $X$. \n",
    "\n",
    "$X = f(Z), Y = h(X) + \\eta_Y, Z = \\eta_Z$\n",
    "\n",
    "One might argue that in complex processes unresolved processes almost always introduce non-deterministic relationships. \n",
    "\n",
    "Here, $l(X; Y | Z)$ denotes the conditional mutual information.\n",
    "\n",
    "3. Purely non-pairwise dependencies:\n",
    "\n",
    "Here $l(X; Y) = l(Z; Y) = 0$ even though both are connected to $Y$.\n",
    "\n",
    "$Y = X \\lor Z + \\eta_Y, P(X = 0, 1) = P(Z = 0, 1) = 0.5$\n",
    "\n",
    "For $P(X) \\ne P(Z)$ faithfulness is not violated anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumption 4 (Causal sufficiency)\n",
    "* One observes (samples from) the marginal distribution $p(w) = \\int p(w, l) dl$ with $L = X \\backslash W$ of the observational distribution $p(x)$ over a causally sufficient subset $W \\subset X$ of variables. \n",
    "* Variables in $W$ are called observed, variables in $L$ are called unobserved.\n",
    "\n",
    "Hidden common cause:\n",
    "\n",
    "* An unobserved variable $L_i \\in L = X \\backslash W$ is a hidden common cause of two distinct observed variables $W_1, W_2 \\in W$ if there are directed paths $\\pi_1$ and $\\pi_2$ from $L_i$ to, respectively, $W_1$ and $W_2$, that intersect only at vertices in $L$.\n",
    "\n",
    "Causal sufficiency: A subset of variables $W \\subset X$ is causally sufficient, if there is no pair of distinct observed vertices $W_1, W_2 \\in W$ with a hidden common cause."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Can there be distinct DAGs G and G' that convey the exact same set of d-separations?\n",
    "\n",
    "Relevance: If yes, then such G and G'\n",
    "* are Bayesian networks for the same set of probability distributions\n",
    "* can without further assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov equivalence: Two DAGS G and G' are Markov equivalent, also referred to as observationally equivalent and denoted G \\sim G', if they have the same set of vertices and any d-separation in one graph corresponds to another d-separation in the other one.\n",
    "\n",
    "Define Markov equivalence class (set of graphs) on a similar fashion, \n",
    "\n",
    "Example 1: \n",
    "* $[X, Y]_{X \\bowtie Y}$ with d-separation $X \\bowtie Y$\n",
    "* $[X, Y]_{X \\not\\bowtie Y} := \\{X \\to Y, Y \\to X\\}$ with no d-separations\n",
    "* In the fundamental case of two dependent random variables we can without further assumptions not decide whether $X \\to Y$ or $Y \\to X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition: Unshielded triple\n",
    "\n",
    "Three vertices X, Y and Z form an unshielded triple $(X, Y, Z)$ if\n",
    "1. X and Y are adjacent\n",
    "2. Z and Y are adjacent\n",
    "3. X and Z are not adjacent\n",
    "\n",
    "Definition: v-structure\n",
    "\n",
    "An unshielded triple $(X, Y, Z)$ forms a v-structure, also called immorality, if $X \\to Y \\leftarrow Z$, also $Y$ is a collider node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theorem: Characterization of Markov equivalence\n",
    "\n",
    "Two DAGs are Markov equivalent if and only if\n",
    "1. they have the same skeleton and \n",
    "2. they have the same v-structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw all DAGs that are Markov equivalent to the DAG shown below on the left hand side.\n",
    "\n",
    "Skeleton: W, X, Y, Z\n",
    "\n",
    "X and Z is a v-structure\n",
    "* Switch X and W\n",
    "* Switch Z and W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphically represent the entire Markov equivalence class of a DAG in a single graph that shows:\n",
    "1. the common features\n",
    "2. and the differences\n",
    "\n",
    "of all members of the equivalence class\n",
    "\n",
    "The CPDAG (completed partially directed acyclic graph) of a DAG $G$ is the graph with the following properties:\n",
    "1. It has the same skeleton as G\n",
    "2. It has an edge $X \\to Y$ if $X \\to Y$ in all $G' \\in [G]$\n",
    "3. It has an edge $X \\leftrightarrow Y$ if there are $G'_1, G'_2 \\in [G]$ such that $X \\to Y$ in $G'_1$ and $X \\leftarrow Y$ in $G'_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Learn CPDAG of causal graph from conditional independencies in observational distribution"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
